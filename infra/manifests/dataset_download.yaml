apiVersion: batch/v1
kind: Job
metadata:
  name: stanfordnlp-imdb-dataset-sync
spec:
  template:
    spec:
      containers:
      - name: dataset-sync
        image: ubuntu:20.04
        command:
        - /bin/bash
        - -c
        - |
          # Install required packages
          apt-get update && apt-get install -y \
            python3-pip \
            wget \
            curl \
            git

          # Install Python packages
          pip3 install huggingface_hub datasets

          # Install MinIO client
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          mv mc /usr/local/bin/

          # Configure MinIO client
          mc alias set myminio http://minio.minio-internal.svc.cluster.local:9000 $MINIO_ACCESS_KEY $MINIO_SECRET_KEY

          # Create bucket if it doesn't exist
          mc mb myminio/datasets --ignore-existing

          # Create temporary directory for dataset
          mkdir -p /tmp/dataset

          # Download dataset from Hugging Face and save to disk
          python3 -c "from datasets import load_dataset; dataset = load_dataset('stanfordnlp/imdb'); dataset.save_to_disk('/tmp/dataset')"

          # Upload to MinIO
          mc cp -r /tmp/dataset/ myminio/datasets/imdb/

          # Cleanup
          rm -rf /tmp/dataset
        env:
        - name: MINIO_ACCESS_KEY
          value: "minioadmin"
        - name: MINIO_SECRET_KEY
          value: "minioadmin"
      restartPolicy: Never
  backoffLimit: 4
